@article{Reich2016,
abstract = {ABSTRACTStatistical prediction models inform decision-making processes in many real-world settings. Prior to using predictions in practice, one must rigorously test and validate candidate models to ensure that the proposed predictions have sufficient accuracy to be used in practice. In this article, we present a framework for evaluating time series predictions, which emphasizes computational simplicity and an intuitive interpretation using the relative mean absolute error metric. For a single time series, this metric enables comparisons of candidate model predictions against na{\"{i}}ve reference models, a method that can provide useful and standardized performance benchmarks. Additionally, in applications with multiple time series, this framework facilitates comparisons of one or more models' predictive performance across different sets of data. We illustrate the use of this metric with a case study comparing predictions of dengue hemorrhagic fever incidence in two provinces of Thailand. This example demonstra...},
author = {Reich, Nicholas G and Lessler, Justin and Sakrejda, Krzysztof and Lauer, Stephen A and Iamsirithaworn, Sopon and Cummings, Derek A T},
journal = {The American Statistician},
number = {3},
pages = {285--292},
publisher = {Taylor {\&} Francis},
title = {{Case Study in Evaluating Time Series Prediction Models Using the Relative Mean Absolute Error}},
url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1148631 papers2://publication/doi/10.1080/00031305.2016.1148631},
volume = {70},
year = {2016}
}
@article{Gneiting2007,
author = {Gneiting, Tilmann and Raftery, Adrian E},
file = {::},
journal = {Journal of the American Statistical Association},
number = {477},
pages = {359--378},
publisher = {Taylor {\&} Francis Group },
title = {{Strictly proper scoring rules, prediction, and estimation}},
url = {http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2{\&}SrcAuth=mekentosj{\&}SrcApp=Papers{\&}DestLinkType=FullRecord{\&}DestApp=WOS{\&}KeyUT=000244361000032 papers2://publication/doi/10.1198/016214506000001437},
volume = {102},
year = {2007}
}
@misc{DELPHI,
author = {DELPHI},
title = {{Real-time Epidemiological Data API}},
url = {https://github.com/cmu-delphi/delphi-epidata},
urldate = {2018-01-25}
}
@misc{PhiResearchLab,
author = {PhiResearchLab},
title = {{Epidemic Prediction Initiative}},
url = {https://predict.phiresearchlab.org/},
urldate = {2018-01-25}
}
@article{Biggerstaff2016,
abstract = {Early insights into the timing of the start, peak, and intensity of the influenza season could be useful in planning influenza prevention and control activities. To encourage development and innovation in influenza forecasting, the Centers for Disease Control and Prevention (CDC) organized a challenge to predict the 2013–14 Unites States influenza season. Challenge contestants were asked to forecast the start, peak, and intensity of the 2013–2014 influenza season at the national level and at any or all Health and Human Services (HHS) region level(s). The challenge ran from December 1, 2013–March 27, 2014; contestants were required to submit 9 biweekly forecasts at the national level to be eligible. The selection of the winner was based on expert evaluation of the methodology used to make the prediction and the accuracy of the prediction as judged against the U.S. Outpatient Influenza-like Illness Surveillance Network (ILINet). Nine teams submitted 13 forecasts for all required milestones. The first forecast was due on December 2, 2013; 3/13 forecasts received correctly predicted the start of the influenza season within one week, 1/13 predicted the peak within 1 week, 3/13 predicted the peak ILINet percentage within 1 {\%}, and 4/13 predicted the season duration within 1 week. For the prediction due on December 19, 2013, the number of forecasts that correctly forecasted the peak week increased to 2/13, the peak percentage to 6/13, and the duration of the season to 6/13. As the season progressed, the forecasts became more stable and were closer to the season milestones. Forecasting has become technically feasible, but further efforts are needed to improve forecast accuracy so that policy makers can reliably use these predictions. CDC and challenge contestants plan to build upon the methods developed during this contest to improve the accuracy of influenza forecasts.},
author = {Biggerstaff, Matthew and Alper, David and Dredze, Mark and Fox, Spencer and Fung, Isaac Chun-Hai and Hickmann, Kyle S. and Lewis, Bryan and Rosenfeld, Roni and Shaman, Jeffrey and Tsou, Ming-Hsiang and Velardi, Paola and Vespignani, Alessandro and Finelli, Lyn},
doi = {10.1186/s12879-016-1669-x},
file = {::},
issn = {1471-2334},
journal = {BMC Infectious Diseases},
keywords = {Infectious Diseases,Internal Medicine,Medical Microbiology,Parasitology,Tropical Medicine},
month = {dec},
number = {1},
pages = {357},
publisher = {BioMed Central},
title = {{Results from the centers for disease control and prevention's predict the 2013–2014 Influenza Season Challenge}},
url = {http://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-016-1669-x},
volume = {16},
year = {2016}
}
@article{Shaman2013,
abstract = {Recently, we developed a seasonal influenza prediction system that uses an advanced data assimilation technique and real-time estimates of influenza incidence to optimize and initialize a population-based mathematical model of influenza transmission dynamics. This system was used to generate and evaluate retrospective forecasts of influenza peak timing in New York City. Here we present weekly forecasts of seasonal influenza developed and run in real time for 108 cities in the USA during the recent 2012–2013 season. Reliable ensemble forecasts of influenza outbreak peak timing with leads of up to 9 weeks were produced. Forecast accuracy increased as the season progressed, and the forecasts significantly outperformed alternate, analogue prediction methods. By week 52, prior to peak for the majority of cities, 63{\%} of all ensemble forecasts were accurate. To our knowledge, this is the first time predictions of seasonal influenza have been made in real time and with demonstrated accuracy.},
author = {Shaman, Jeffrey and Karspeck, Alicia and Yang, Wan and Tamerius, James and Lipsitch, Marc},
file = {::},
journal = {Nature Communications},
title = {{Real-time influenza forecasts during the 2012–2013 season}},
url = {http://www.nature.com/doifinder/10.1038/ncomms3837 papers2://publication/doi/10.1038/ncomms3837},
volume = {4},
year = {2013}
}
@article{Shaman2012,
abstract = {Influenza recurs seasonally in temperate regions of the world; however, our ability to predict the timing, duration, and magnitude of local seasonal outbreaks of influenza remains limited. Here we develop a framework for initializing real-time forecasts of seasonal influenza outbreaks, using a data assimilation technique commonly applied in numerical weather prediction. The availability of real-time, web-based estimates of local influenza infection rates makes this type of quantitative forecasting possible. Retrospective ensemble forecasts are generated on a weekly basis following assimilation of these web-based estimates for the 2003-2008 influenza seasons in New York City. The findings indicate that real-time skillful predictions of peak timing can be made more than 7 wk in advance of the actual peak. In addition, confidence in those predictions can be inferred from the spread of the forecast ensemble. This work represents an initial step in the development of a statistically rigorous system for real-time forecast of seasonal influenza.},
address = {Department of Environmental Health Sciences, Mailman School of Public Health, Columbia University, New York, NY 10032, USA. jls106@columbia.edu},
author = {Shaman, Jeffrey and Karspeck, Alicia},
file = {::},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {50},
pages = {20425--20430},
title = {{Forecasting seasonal outbreaks of influenza.}},
url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed{\&}id=23184969{\&}retmode=ref{\&}cmd=prlinks papers2://publication/doi/10.1073/pnas.1208772109},
volume = {109},
year = {2012}
}
@article{Yamana2017,
author = {Yamana, Teresa K. and Kandula, Sasikiran and Shaman, Jeffrey},
doi = {10.1371/journal.pcbi.1005801},
editor = {Lessler, Justin},
file = {::},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {nov},
number = {11},
pages = {e1005801},
publisher = {Public Library of Science},
title = {{Individual versus superensemble forecasts of seasonal influenza outbreaks in the United States}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1005801},
volume = {13},
year = {2017}
}
@article{Brooks2015,
author = {Brooks, Logan C. and Farrow, David C. and Hyun, Sangwon and Tibshirani, Ryan J. and Rosenfeld, Roni and Molinari, NAM and Ortega-Sanchez, IR and Messonnier, ML and Thompson, WW and Wortley, PM and Weintraub, E and Laporte, RE and Hethcote, HW and Laneri, K and Bhadra, A and Ionides, EL and Bouma, M and Dhiman, RC and Yadav, RS and King, AA and Ionides, EL and Pascual, M and Bouma, MJ and Ferguson, NM and Cummings, DA and Fraser, C and Cajka, JC and Cooley, PC and Burke, DS and Colizza, V and Barrat, A and Barthelemy, M and Valleron, AJ and Vespignani, A and Bansal, S and Pourbohloul, B and Meyers, LA and Lee, BY and Brown, ST and Cooley, P and Potter, MA and Wheaton, WD and Voorhees, RE and Grefenstette, JJ and Brown, ST and Rosenfeld, R and DePasse, J and Stone, NT and Cooley, PC and Ferrari, S and Cribari-Neto, F and Simas, AB and Barreto-Souza, W and Rocha, AV and Box, GE and Jenkins, GM and Sakia, R and Shumway, RH and Stoffer, DS and Dugas, AF and Jalalpour, M and Gel, Y and Levin, S and Torcaso, F and Igusa, T and Chretien, JP and George, D and Shaman, J and Chitale, RA and McKenzie, FE and Nsoesie, EO and Brownstein, JS and Ramakrishnan, N and Marathe, MV and Shaman, J and Karspeck, A and Ong, JBS and Chen, MIC and Cook, AR and Lee, HC and Lee, VJ and Lin, RTP and Nsoesie, EO and Mararthe, M and Brownstein, J and Goldstein, E and Cobey, S and Takahashi, S and Miller, JC and Lipsitch, M and Vergu, E and Grais, RF and Sarter, H and Fagot, JP and Lambert, B and Valleron, AJ and Soebiyanto, RP and Adimi, F and Kiang, RK and Araz, OM and Bentley, D and Muelleman, RL and Polgreen, PM and Nelson, FD and Neumann, GR and Viboud, C and Bo{\"{e}}lle, PY and Carrat, F and Valleron, AJ and Flahault, A and Shaman, J and Karspeck, A and Yang, W and Tamerius, J and Lipsitch, M and Yang, W and Karspeck, A and Shaman, J and Brammer, L and Budd, AP and Finelli, L and Ginsberg, J and Mohebbi, MH and Patel, RS and Brammer, L and Smolinski, MS and Brilliant, L and Cook, S and Conrad, C and Fowlkes, AL and Mohebbi, MH and Copeland, P and Romano, R and Zhang, T and Hecht, G and Zigmond, D and Stefansen, C and Lazer, D and Kennedy, R and King, G and Vespignani, A and Santillana, M and Zhang, DW and Althouse, BM and Ayers, JW and Lamb, A and Paul, MJ and Dredze, M and Tibshirani, RJ and Lehmann, EL and Casella, G and van Panhuis, WG and Hyun, S and Blaney, K and Jr, ET Marques and Coelho, GE and Jr, JB Siqueira and Liu, JS and Eddelbuettel, D and Fran{\c{c}}ois, R and Eddelbuettel, D and Tange, O},
doi = {10.1371/journal.pcbi.1004382},
editor = {Tanaka, Mark M.},
file = {::;::},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {aug},
number = {8},
pages = {e1004382},
publisher = {Public Library of Science},
title = {{Flexible Modeling of Epidemics with an Empirical Bayes Framework}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004382},
volume = {11},
year = {2015}
}
@article{Yamana2016,
abstract = {In recent years, a number of systems capable of predicting future infectious disease incidence have been developed. As more of these systems are operationalized, it is important that the forecasts generated by these different approaches be formally reconciled so that individual forecast error and bias are reduced. Here we present a first example of such multi-system, or superensemble, forecast. We develop three distinct systems for predicting dengue, which are applied retrospectively to forecast outbreak characteristics in San Juan, Puerto Rico. We then use Bayesian averaging methods to combine the predictions from these systems and create superensemble forecasts. We demonstrate that on average, the superensemble approach produces more accurate forecasts than those made from any of the individual forecasting systems.},
author = {Yamana, Teresa K and Kandula, Sasikiran and Shaman, Jeffrey},
file = {::},
journal = {Journal of The Royal Society Interface},
number = {123},
pages = {20160410},
publisher = {The Royal Society},
title = {{Superensemble forecasts of dengue outbreaks}},
url = {http://rsif.royalsocietypublishing.org/content/13/123/20160410.abstract papers2://publication/doi/10.1098/rsif.2016.0410},
volume = {13},
year = {2016}
}
@article{Scarpino2017,
abstract = {Infectious disease outbreaks recapitulate biology: they emerge from the multi-level interaction of hosts, pathogens, and their shared environment. As a result, predicting when, where, and how far diseases will spread requires a complex systems approach to modeling. Recent studies have demonstrated that predicting different components of outbreaks--e.g., the expected number of cases, pace and tempo of cases needing treatment, importation probability etc.--is feasible. Therefore, advancing both the science and practice of disease forecasting now requires testing for the presence of fundamental limits to outbreak prediction. To investigate the question of outbreak prediction, we study the information theoretic limits to forecasting across a broad set of infectious diseases using permutation entropy as a model independent measure of predictability. Studying the predictability of a diverse collection of historical outbreaks--including, gonorrhea, influenza, Zika, measles, polio, whooping cough, and mumps--we identify a fundamental entropy barrier for time series forecasting. However, we find that for most diseases this barrier to prediction is often well beyond the time scale of single outbreaks, implying prediction is likely to succeed. We also find that the forecast horizon varies by disease and demonstrate that both shifting model structures and social network heterogeneity are the most likely mechanisms for the observed differences in predictability across contagions. Our results highlight the importance of moving beyond time series forecasting, by embracing dynamic modeling approaches to prediction and suggest challenges for performing model selection across long disease time series. We further anticipate that our findings will contribute to the rapidly growing field of epidemiological forecasting and may relate more broadly to the predictability of complex adaptive systems.},
archivePrefix = {arXiv},
arxivId = {1703.07317},
author = {Scarpino, Samuel V. and Petri, Giovanni},
eprint = {1703.07317},
file = {::},
month = {mar},
title = {{On the predictability of infectious disease outbreaks}},
url = {http://arxiv.org/abs/1703.07317},
year = {2017}
}
@article{Funk2017,
author = {Funk, Sebastian and Camacho, Anton and Kucharski, Adam J. and Lowe, Rachel and Eggo, Rosalind M. and Edmunds, W. John},
journal = {bioRxiv},
title = {{Assessing the performance of real-time epidemic forecasts}},
url = {http://www.biorxiv.org/content/early/2017/08/18/177451},
year = {2017}
}
@article{Johansson2016,
abstract = {Dengue viruses, which infect millions of people per year worldwide, cause large epidemics that strain healthcare systems. Despite diverse efforts to develop forecasting tools including autoregressive time series, climate-driven statistical, and mechanistic biological models, little work has been done to understand the contribution of different components to improved prediction. We developed a framework to assess and compare dengue forecasts produced from different types of models and evaluated the performance of seasonal autoregressive models with and without climate variables for forecasting dengue incidence in Mexico. Climate data did not significantly improve the predictive power of seasonal autoregressive models. Short-term and seasonal autocorrelation were key to improving short-term and long-term forecasts, respectively. Seasonal autoregressive models captured a substantial amount of dengue variability, but better models are needed to improve dengue forecasting. This framework contributes to the sparse literature of infectious disease prediction model evaluation, using state-of-the-art validation techniques such as out-of-sample testing and comparison to an appropriate reference model.},
author = {Johansson, Michael A and Reich, Nicholas G and Hota, Aditi and Brownstein, John S and Santillana, Mauricio},
doi = {10.1038/srep33707},
file = {::},
issn = {2045-2322},
journal = {Scientific reports},
month = {sep},
pages = {33707},
pmid = {27665707},
publisher = {Nature Publishing Group},
title = {{Evaluating the performance of infectious disease forecasts: A comparison of climate-driven and seasonal dengue forecasts for Mexico.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27665707 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5036038},
volume = {6},
year = {2016}
}
@article{Ray2017,
author = {Ray, Evan L. and Sakrejda, Krzysztof and Lauer, Stephen A. and Johansson, Michael A. and Reich, Nicholas G.},
doi = {10.1002/sim.7488},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {copula,dengue fever,infectious disease,influenza,kernel conditional density estimation,prediction},
month = {sep},
title = {{Infectious disease prediction with kernel conditional density estimation}},
url = {http://doi.wiley.com/10.1002/sim.7488},
year = {2017}
}
@article{Polikar2006, 
author={R. Polikar}, 
journal={IEEE Circuits and Systems Magazine}, 
title={Ensemble based systems in decision making}, 
year={2006}, 
volume={6}, 
number={3}, 
pages={21-45}, 
abstract={In matters of great importance that have financial, medical, social, or other implications, we often seek a second opinion before making a decision, sometimes a third, and sometimes many more. In doing so, we weigh the individual opinions, and combine them through some thought process to reach a final decision that is presumably the most informed one. The process of consulting "several experts" before making a final decision is perhaps second nature to us; yet, the extensive benefits of such a process in automated decision making applications have only recently been discovered by computational intelligence community. Also known under various other names, such as multiple classifier systems, committee of classifiers, or mixture of experts, ensemble based systems have shown to produce favorable results compared to those of single-expert systems for a broad range of applications and under a variety of scenarios. Design, implementation and application of such systems are the main topics of this article. Specifically, this paper reviews conditions under which ensemble based systems may be more beneficial than their single classifier counterparts, algorithms for generating individual components of the ensemble systems, and various procedures through which the individual classifiers can be combined. We discuss popular ensemble based algorithms, such as bagging, boosting, AdaBoost, stacked generalization, and hierarchical mixture of experts; as well as commonly used combination rules, including algebraic combination of outputs, voting based techniques, behavior knowledge space, and decision templates. Finally, we look at current and future research directions for novel applications of ensemble systems. Such applications include incremental learning, data fusion, feature selection, learning with missing features, confidence estimation, and error correcting output codes; all areas in which ensemble systems have shown great promise}, 
keywords={decision making;decision support systems;error correction codes;expert systems;learning (artificial intelligence);learning systems;pattern classification;reviews;sensor fusion;AdaBoost;automated decision making;bagging;behavior knowledge space;boosting;confidence estimation;data fusion;decision templates;ensemble based systems;error correcting output codes;feature selection;incremental learning;multiple classifier systems;single-expert systems;stacked generalization;voting based techniques;Bagging;Boosting;Computational intelligence;Decision making;Error correction codes;Estimation error;Game theory;TV;Telephony;Voting}, 
doi={10.1109/MCAS.2006.1688199}, 
ISSN={1531-636X}, 
month={Third}
}
@article{Viboud2018,
title = "The RAPIDD ebola forecasting challenge: Synthesis and lessons learnt",
journal = "Epidemics",
volume = "22",
pages = "13 - 21",
year = "2018",
note = "The RAPIDD Ebola Forecasting Challenge",
issn = "1755-4365",
doi = "https://doi.org/10.1016/j.epidem.2017.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1755436517301275",
author = "Cécile Viboud and Kaiyuan Sun and Robert Gaffey and Marco Ajelli and Laura Fumanelli and Stefano Merler and Qian Zhang and Gerardo Chowell and Lone Simonsen and Alessandro Vespignani",
keywords = "Ebola epidemic, Mathematical modeling, Forecasting challenge, Model comparison, Synthetic data, Prediction performance, Prediction horizon, Data accuracy",
abstract = "Infectious disease forecasting is gaining traction in the public health community; however, limited systematic comparisons of model performance exist. Here we present the results of a synthetic forecasting challenge inspired by the West African Ebola crisis in 2014–2015 and involving 16 international academic teams and US government agencies, and compare the predictive performance of 8 independent modeling approaches. Challenge participants were invited to predict 140 epidemiological targets across 5 different time points of 4 synthetic Ebola outbreaks, each involving different levels of interventions and “fog of war” in outbreak data made available for predictions. Prediction targets included 1–4 week-ahead case incidences, outbreak size, peak timing, and several natural history parameters. With respect to weekly case incidence targets, ensemble predictions based on a Bayesian average of the 8 participating models outperformed any individual model and did substantially better than a null auto-regressive model. There was no relationship between model complexity and prediction accuracy; however, the top performing models for short-term weekly incidence were reactive models with few parameters, fitted to a short and recent part of the outbreak. Individual model outputs and ensemble predictions improved with data accuracy and availability; by the second time point, just before the peak of the epidemic, estimates of final size were within 20\% of the target. The 4th challenge scenario − mirroring an uncontrolled Ebola outbreak with substantial data reporting noise − was poorly predicted by all modeling teams. Overall, this synthetic forecasting challenge provided a deep understanding of model performance under controlled data and epidemiological conditions. We recommend such “peace time” forecasting challenges as key elements to improve coordination and inspire collaboration between modeling groups ahead of the next pandemic threat, and to assess model forecasting accuracy for a variety of known and hypothetical pathogens."
}
@article{Biggerstaff2018,
title = "Results from the second year of a collaborative effort to forecast influenza seasons in the United States",
journal = "Epidemics",
year = "2018",
issn = "1755-4365",
doi = "https://doi.org/10.1016/j.epidem.2018.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S1755436517300889",
author = "Matthew Biggerstaff and Michael Johansson and David Alper and Logan C. Brooks and Prithwish Chakraborty and David C. Farrow and Sangwon Hyun and Sasikiran Kandula and Craig McGowan and Naren Ramakrishnan and Roni Rosenfeld and Jeffrey Shaman and Rob Tibshirani and Ryan J. Tibshirani and Alessandro Vespignani and Wan Yang and Qian Zhang and Carrie Reed",
keywords = "Influenza, Epidemics, Forecasting, Prediction, Modeling",
abstract = "Accurate forecasts could enable more informed public health decisions. Since 2013, CDC has worked with external researchers to improve influenza forecasts by coordinating seasonal challenges for the United States and the 10 Health and Human Service Regions. Forecasted targets for the 2014–15 challenge were the onset week, peak week, and peak intensity of the season and the weekly percent of outpatient visits due to influenza-like illness (ILI) 1–4 weeks in advance. We used a logarithmic scoring rule to score the weekly forecasts, averaged the scores over an evaluation period, and then exponentiated the resulting logarithmic score. Poor forecasts had a score near 0, and perfect forecasts a score of 1. Five teams submitted forecasts from seven different models. At the national level, the team scores for onset week ranged from <0.01 to 0.41, peak week ranged from 0.08 to 0.49, and peak intensity ranged from <0.01 to 0.17. The scores for predictions of ILI 1–4 weeks in advance ranged from 0.02–0.38 and was highest 1 week ahead. Forecast skill varied by HHS region. Forecasts can predict epidemic characteristics that inform public health actions. CDC, state and local health officials, and researchers are working together to improve forecasts."
}
@article{Ray2018,
    author = {Ray, Evan L. AND Reich, Nicholas G.},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {Prediction of infectious disease epidemics via weighted density ensembles},
    year = {2018},
    month = {02},
    volume = {14},
    url = {https://doi.org/10.1371/journal.pcbi.1005910},
    pages = {1-23},
    abstract = {Author summary Public health agencies such as the US Centers for Disease Control and Prevention would like to have as much information as possible when planning interventions intended to reduce and prevent the spread of infectious disease. For instance, accurate and reliable predictions of the timing and severity of the influenza season could help with planning how many influenza vaccine doses to produce and by what date they will be needed. Many different mathematical and statistical models have been proposed to model influenza and other infectious diseases, and these models have different strengths and weaknesses. In particular, one or another of these model specifications is often better than the others in different seasons, at different times within the season, and for different prediction targets (such as different measures of the timing or severity of the influenza season). In this article, we explore ensemble methods that combine predictions from multiple “component” models. We find that these ensemble methods do about as well as the best of the component models in terms of aggregate performance across multiple seasons, but that the ensemble methods have more consistent performance across different seasons. This improved consistency is valuable for planners who need predictions that can be trusted under all circumstances.},
    number = {2},
    doi = {10.1371/journal.pcbi.1005910}
}
@article {Gneiting2005,
	author = {Gneiting, Tilmann and Raftery, Adrian E.},
	title = {Weather Forecasting with Ensemble Methods},
	volume = {310},
	number = {5746},
	pages = {248--249},
	year = {2005},
	doi = {10.1126/science.1115255},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/310/5746/248},
	eprint = {http://science.sciencemag.org/content/310/5746/248.full.pdf},
	journal = {Science}
}
@misc{ILINet, 
	author={Centers for Disease Control and Prevention}
	title={{Overview of Influenza Surveillance in the United States}},
	 url={https://www.cdc.gov/flu/weekly/overview.htm}, 
	urldate = {2018-04-23}, 
	year={2017}, month={Oct}
}