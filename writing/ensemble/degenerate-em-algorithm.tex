\documentclass{article}
\usepackage[letterpaper, margin=1in]{geometry} % margin

\title{EM Algorithm for Weighted Density Ensembles}

\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{parskip}        % for spacing after paragraphs http://ctan.org/pkg/parskip
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\author{Nicholas G Reich}


\begin{document}

\maketitle

The following is adapted from online documents\footnote{\url{https://www.cs.cmu.edu/~roni/11761/Presentations/degenerateEM.pdf} and \url{http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/11761-s97/WWW/tex/EM.ps}} and describes the use of the degnerate EM algorithm for constructing weighted average ensemble models in the context of infectious disease forecasting.  
%As described in Reich et al. (see comparison manuscript from FluSight Network), we are operating in the setting where we have a set of $M$ component models that make forecasts across a set of regions ($r$), targets ($t$), seasons ($s$), and weeks ($w$). 
%A specific predictive density across each of these dimensions can be represented as $f_{m,r,t,s,w}(z|\bf{x})$ where $\bf{x}$ represents data conditioned on by the model and $z$ represents the target variable of interest.
%Our models are evaluated using the log-score which can be represented as 
%\begin{eqnarray}
%LS_{m,r,t,s,w} & = & \log f_{m,r,t,s,w}(z^*|{\bf x}). \label{eqn:logscore}
%\end{eqnarray}
We aim to develop a weighted density ensemble that combines the full predictive distributions in such a way as to optimize the score of the resulting model average.

%\section{The Algorithm}
Assume that we have a set of $M$ fitted predictive densities ``evaluated at''\footnote{Need to add distinction about not strict evaluation but rather probability assigned to ``values deemed to be accurate''.} observed data\footnote{For now, these could be forecasts for arbitrary targets, locations, seasons, etc... } $z_i^*$ for $i=1, ..., N$. We will notate these data as  $f_{m}(z^*|{\bf x})$. There will be $M\cdot N$ total observations, as each model must have an associated value (a probability, between 0 and 1) for each observed data point.

We wish to obtain a set of optimal weights $\tilde\pi = \{\tilde\pi_1, \tilde\pi_2, ..., \tilde\pi_M\}$ for combining the models such that $\forall m$ $\tilde\pi_m \geq 0$ and $\sum_{m=1}^M \tilde\pi_m=1$.
The weights can be used to then combine the component models into an ensemble model as
$$f(z_i|\pi) = \sum_{m=1}^M \pi_m f_m(z_i).$$
We define a function $\ell(\pi)$ that computes a log-likelihood\footnote{Is this assuming independence?} of the resulting ensemble as follows:
$$\ell(\pi) = \frac{1}{N}\sum_{i=1}^N \log f(z_i|\pi).$$

Below, we define one procedure to obtain a set of weights for the ensemble.

\begin{algorithm}
\caption{Degenerate Expectation Maximization (DEM) algorithm}\label{alg:DEM}
\begin{algorithmic}[1]
\Procedure{dem}{$...$}%\Comment{The g.c.d. of a and b}
\State Initialize $\pi_m^{(0)}$ such that $\forall m$ $\pi_m^{(0)} \geq 0$ and $\sum_{m=1}^M \pi_m^{(0)}=1$ 
\State Set $t=0$
\State Set $\Delta=1$, or another arbitrary constant.
\State Set $\epsilon$ to be a very small positive number strictly less than $\Delta$.
\While{$ \Delta > \epsilon$}%\Comment{We have the answer if r is 0}
\State Set $t=t+1$
\State Update weights, $\forall m$, $\pi_m^{(t)} = \frac{1}{N}\sum_{i=1}^N \frac{\pi_m^{(t-1)}f_m(z_i)}{f(z_i|\pi^{(t-1)})}$
\State Set $\Delta =  \frac{\ell(\pi^{(t)}) - \ell(\pi^{(t-1)})}{|\ell(\pi^{(t)})|}$ \label{delta-step}
\EndWhile
\State \textbf{return} $\tilde\pi = \tilde\pi^{(t)}$%\Comment{The gcd is b}
\EndProcedure
\end{algorithmic}
\end{algorithm}

And note that in Algorithm \ref{alg:DEM}, Step \ref{delta-step} it should always be the case that $\ell(t) \geq \ell(t-1)$.


\end{document}