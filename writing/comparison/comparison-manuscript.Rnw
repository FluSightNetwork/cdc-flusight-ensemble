\documentclass{article}

\title{Comparing Mechanistic and Statistical Models to Forecast Influenza in the U.S.}

\author{Nicholas G Reich, Logan Brooks, Craig McGowan, Sasikiran Kandula, \\ Dave Osthus, Evan Ray, Roni Rosenfeld, Jeffrey Shaman, \\Abhinav Tushar, Teresa Yamana}

\usepackage[letterpaper, margin=1in]{geometry} % margin
\usepackage{lineno}% add line numbers
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{parskip}        % for spacing after paragraphs http://ctan.org/pkg/parskip
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{amsmath, amsfonts}
\usepackage{setspace}

\linenumbers % line numbers
\onehalfspacing

% For computer modern sans serif
\usepackage[T1]{fontenc}
\renewcommand*\familydefault{\sfdefault} %% Only if the base font of the document is to be sans serif


\begin{document}

\maketitle

\tableofcontents

\section{Introduction}
Forecasts of infectious disease outbreaks can inform public health response to outbreaks. Close collaboration between public health policy-makers and quantitative modelers is necessary to ensure the forecasts have maximum impact and are appropriately communicated to the public and the broader public health community. 

Infectious disease modeling has proven to be fertile ground for statisticians, mathematicians, and quantitative modelers for over a century. Yet there is not a consensus on a single best modeling approach or method for forecasting the dynamic patterns of infectious disease outbreaks, in both endemic and emergent settings. Mechanistic models consider the biological underpinnings of disease transmission, and are in practice are typically implemented as variants on the Susceptible-Infectious-Recovered (SIR) model. Phenomenological models ignore the biological underpinnings and theory of disease transmission and focus instead on using data-driven, empirical and statistical approahces to make the best forecasts possible of a given dataset, or phenomenon. Both approaches are commonly used and both have advantages and disadvantages in different settings.


\section{Methods}

\subsection{FluSight Challenge Overview}

\begin{itemize}
    \item point to papers about FluSight
    \item define targets, predictive distributions, times at which predictions are made
\end{itemize}

\subsection{Description of this Forecasting Experiment}

\subsection{Summary of Models}

%% Table with columns for:
%%   - institution
%%   - model name
%%   - underlying method
%%   - statistical/mechanistic
%%   - non-ILI data sources

\subsection{Metrics Used for Evaluation and Comparison}

\begin{itemize}
    \item log-score for predictive distribution, aggregated by (model), (model x season), (model x season x location), (model x season x target-type), (model x season x target), , (model x season x week)
    \item MAE for point predictions
    \item permutation test for pairwise statistical comparison between two models
    \item beta regression or permutation test for comparison between groups of models (i.e. mechanistic vs. statistical)
\end{itemize}


\section{Results}

\subsection{Overall performance of models}


\subsection{Performance of models by location}


\subsection{Performance of models by target}


\subsection{Performance of models by time-of-season}


\subsection{Comparison between statistical and mechanistic models}


\section{Discussion}

\subsection{Overview of key results and importance}
The first large-scale comparison of flu forecasting models from different modeling teams/philosophies across multiple years.

\subsection{Overview of statistical vs. mechanistic model comparison}
As our knowledge/data about the system mature, we expect mechanistic models to be better, but when true signals of mechanistic model is drowned out by observational noise or spatial aggregation, statistical models may perform better. This comparison is a barometer for where 

\subsection{Limitations}

\begin{itemize}
    \item relatively few additional data sources incorporated
    \item no models that explicitly incorporate strain information
    \item no models with spatial information included
    \item seven seasons of data is not a lot (n=7) to draw strong conclusions about comparative model performance
\end{itemize}


\end{document}